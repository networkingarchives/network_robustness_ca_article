---
title: 'The Measure of the Archive: The Robustness of Network Analysis in the Light
  of Missing Data'
output:
  bookdown::pdf_book:
    toc: false
    keep_tex: true
    citation_package: biblatex
  word_document: default
  html_notebook: default
header-includes: 
 - \usepackage{xcolor}
always_allow_html: true
bibliography: network_robustness_biblio.bib
---

# Introduction

The archives that historians work with are filled with traces of damaged, lost, and destroyed letters, which, had they survived, might have profoundly changed established historical narratives. Sometimes these archival gaps are created during the lifetime of the individual in question: fleeing persecution in Catholic-run Bohemia, the theologian, pedagogue and minister Jan Comenius took refuge in Leszno in Poland, where he administered a school and was made the leader of the Moravian and Bohemian churches. In 1656, during the Swedish invasion of Poland, Comenius had declared his support for the Swedish side. In retaliation, the Polish Catholic partisans burned down Comenius's town, including his school. According to John Pell, both Comenius and the town's inhabitants had resolved not to remove any goods from the town but rather to weather the coming storm. This was a mistake, wrote Pell in a letter to Samuel Hartlib: the army burned Lesna to the ground, along with Comenius' writings and even the town's archives. In the letter he wrote:

> They did not fear that he would abandon them as long as his books and writings were not sent from thence. Thus they have lost both his manuscripts and their own records &c which might have deserved an exception from their general resolution of sending nothing out of Lesna.[^1]

[^1]: John Pell to Samuel Hartlib. Zürich, 27 July 1656. BL Add MS 4280, 37r-v. Digital version of printed transcription consulted, in Jana Amosa Komenského korrespondence. Ed. Adolf Patera. Prague: 1892. No. 159. Found in Early Modern Letters Online [<http://tinyurl.com/yaumwclk>]

This was not the first time Comenius had witnessed the destruction of his records: he had a similar loss in Fulnek, Moravia, in 1623, not to mention the less violent loss of documents associated with a life of exile [@urbanek_comenius_2014, p. 31]. This quotation above illustrates the contemporary perception of the value of written records, and the corresponding loss when they were destroyed. What might have been lost in this invaluable cache of letters, books and documents? It would almost certainly cause us to revise our understanding of Comenius's network, and the intellectual exchange of which he was a part.

In other cases, a correspondence archive is affected by missing data long after the death of the individual at its centre. Since the death of the Anglo-Prussian intelligencer Samuel Hartlib in 1660, users and custodians have, according to Leigh Penman, 'reorganised, subtracted from, and added to [Hartlib's] archive, fundamentally altering its physical and textual make-up.' [@penman_omnium_2016, p. 4.] These additions and subtractions lead to the revision or re-writing of histories, in often substantial ways. Sometimes the additions are on a smaller scale, such as Noel Malcolm's discovery and publication, in 2001, of six new letters from the French intelligencer Marin Mersenne, but even a single added connection might force us to re-visit our understanding of an individual's network [@malcolm_six_2001, p. 95.]. In other cases, the data is partial rather than missing: a piece or group of correspondence data may be missing the name of a sender or recipient, or have some uncertainty because it is unknown whether the Julian or Gregorian calendars were used, for example.

Traditional histories are often rewritten or revised in the light of newly-discovered evidence, but this does not generally hold back existing scholarship: it is rarely argued that one should avoid a topic because there might exist, in unknown quantities, some undiscovered part of their archive---a comment which is sometimes levelled at histories written using quantitative methods. We might think that quantitative measurements, based, as they necessarily are, on seemingly immovable 'hard data', are more at the mercy of missing or uncertain parts of archives. Is this the case in practice? In this paper we explore these effects through one such quantitative method: historical network analysis using correspondence data. What effect might events like those above---leading to the destruction or discovery of letters---have on the quantitative methods and results we use in our writing of histories today? To what extent---if any---should we be cautious of conclusions drawn from quantitative results, given that most archives are partial?

# Historical network analysis

Recent years have seen a growth in the use of historical data to construct and analyse complex networks [for example see @ahnert_protestant_2015; @ahnert_metadata_2019; @bourke_female_2017]. Some of this analysis rests on network visualisation, which typically takes the form of the 'force-directed' network diagram. While such diagrams can provide useful insights for smaller networks they quickly become unhelpful 'hairballs' as the size of the network increases. A more quantitative approach is to use a set of network metrics designed to understand the 'centrality' of a given actor within a network, often with the aim of understanding relationships, roles, or influence. [see @freeman_centrality_1979; @bonacich_factoring_1972; @bonacich_power_1987; @scott_social_1988; @wasserman_social_1994] These metrics operate across a spectrum of complexities. The simplest is the degree of a node, which is its number of connections. This metric can highlight well-connected nodes. The Six Degrees of Francis Bacon project uses the co-occurrence of individuals in entries of the Oxford Dictionary of National Biography (ODNB) to create a probabilistic social network of figures between 1500-1700, and employs degree scores to find influential individuals who do not have their own separate entry in the source material. [@warren_six_2016] Other studies have taken more nuanced approaches. Ahnert and Ahnert use betweenness centrality and eigenvector centrality and compare them to the degree, in order to reveal hidden influencers, who were not necessarily well-connected nodes but who bridged communities and exerted their influence in other ways. [@ahnert_protestant_2015] Betweenness centrality considers all shortest paths between two nodes in the network and counts how often a given node or edge lies on these shortest paths. Eigenvector centrality recursively scores a node on how well it is connected to well-connected nodes: individuals which 'have the ear' of a powerful person may also exert influence in a network. In a follow-on project, Ahnert and Ahnert take an additional five key network measurements to create a 'profile' for each individual, which can then be clustered together to find those with similar roles and even predict likely spies or intelligencers [@ahnert_metadata_2019, p. 42.].

What these studies have in common is that they all, by the nature of their sources, make inferences based on a partial perspective of the network, which results from partial or fragmentary data. Critique around the importance of understanding partial data in the digital humanities is not new, but there are relatively few studies which actually seek to ascertain its impact [@bode_equivalence_2017 for caution; exceptions are @lincoln_modeling_2020; @brosens2019; which both use imputation to model the effect of missing data]. One might think that network analysis would be particularly sensitive to missing data: for example, a measurement of a node's betweenness centrality, which relies on the ability to measure unbroken paths through a network, could potentially produce very different results if a single node in a crucial structural position were removed. Here we model the removal of archival data in a variety of simulated ways from three large correspondence datasets, and measure the sensitivity of the results to this removal. This follows on from work in other areas using complex networks, namely archaeology and the social sciences. We find that the patterns in our datasets broadly align with other disciplines, and suggest that many of the anxieties surrounding the use of metrics in historical network analysis may be unfounded.

A common misconception is that the incompleteness of network data is particularly pertinent in the context of historical data. Network analysis is applied in a vast range of interdisciplinary settings and data sets, from neuroscience, ecology, and molecular biology to computer science, physics, and engineering. Only in very few circumstances is the analysed network complete and accurate. Most of the time connections are either inferred from noisy data or derived from a partial snapshot of the system. Nevertheless network analysis has provided many useful insights into these systems. This is because some results are not affected by missing data, some are affected but can still be interpreted usefully in the light of missing data, and lastly, some results in fact tell us more about the biases and gaps in the data. Our aim in this paper is to establish the extent to which the results of quantitative network analysis are affected by absent data in the particular context of historical correspondence networks.

There is some skepticism around the use of network analysis on large historical datasets, because it is assumed that the survival of letters is low. This mirrors a skepticism in other areas, namely the social sciences, which has been addressed through multiple studies which have looked at the robustness of network analysis measures on sub-samples of an entire network. The advantage of sampling in social network analysis is clear - it can reduce the time or cost of a study by reducing the number or length of interviews, for example. Costenbader and Valente used bootstrap sampling---a method for estimating a statistic by continually resampling and replacing observations in a dataset---of survey responses to measure the stability of 11 measurements of centrality on 59 different networks, and found that although there were variations across networks, in general in-degree (a count of a node's incoming connections) and eigenvector centrality scores were relatively stable even when large portions of the networks were removed. [@costenbader_stability_2003, p. 306]

# Missing data

Missing network data is a common problem in many other fields. Archaeologists are often confronted with highly fragmented data, yet the use of network analysis in their field is established and growing. Leidwanger *et al.* outlined some of the pitfalls of network analysis in archaeology, warning that it can lead to an illusion of objectivity [@leidwanger_manifesto_2014]. Archaeologists often use objects as proxies for relationships between nodes: for example two nodes, island communities, say, might share an edge if the same style of pottery is found in each. This can lead to networks based on very partial data, but it has been shown that most metrics in these networks are robust to node removal [@noauthor_network_nodate].

Social network data is also often incomplete, because of 'boundary specification' problems (difficulties in deciding the boundary of a network), non-response to surveys, or inaccuracy [@kossinets_effects_2006; @laumann_boundary_1983]. In order to evaluate the effect of this incompleteness, Galaskiewicz (1991) compared different types of sampling techniques by evaluating their effect on the in-degree of nodes and on 'popular' versus 'unpopular' actors in the network, and found that some results remained largely unchanged when data was removed, and that the choice of sampling technique did not have much of an effect. [@galaskiewicz_estimating_1991] More recently Smith and Moody measured six metrics across twelve datasets and found that some measurements were particularly sensitive to missing data, and that large centralised networks were more robust. [@smith_structural_2013] In a second study, the effect of non-random subsamples on the network metrics is considered, and it is shown that the removal of more central nodes has a larger effect in general, again with some dependence on the particular metric and the network type.[@smith_network_2017]

Compared with the humanities and social sciences the natural sciences can sometimes give an impression that data incompleteness is less of a problem, due to the control that scientists have over the design and execution of particular experiments. This is illusory however, specifically in the context of network science, which aims to study a wide range of real-world networks, most of which come in the form of highly incomplete and often unreliable datasets. The effect of missing data on network metrics has therefore also received attention in the sciences, and particularly in biology, which often aims to infer networks of physical interaction between proteins as well as networks of regulatory interactions between genes (among other types of networks). This network data is highly incomplete, but in many cases also contains spurious links that do not exist in the living cell. This is because protein-protein networks and gene regulatory networks are often inferred from circumstantial evidence, rather than direct measurements. For example, a DNA 'promoter' sequence close to a particular gene may imply that the 'transcription factor' protein of another gene is able to bind to the DNA at this position, representing a regulatory interaction between these two genes, but this binding event may never actually happen in the cell because the promoter sequence may be physically inaccessible due to the spatial organisation of the DNA. Because of these kinds of uncertainty, the edges of biological interaction networks are typically assigned confidence scores. This poses another problem, which is a general problem of 'weighted' networks.

Most network metrics can be generalised to weighted networks, but the weighted counterparts are often difficult to interpret. As a result weighted networks are often subjected to a threshold in order to turn them into unweighted networks that lend themselves more readily to conventional network metrics. The choice of threshold however is somewhat arbitrary, which is why recent work examines the consequences of this choice of threshold and the resulting variation in the amount of missing data in these networks.[@bozhilova_measuring_2019] The study finds that some measures (including degree and PageRank, a form of eigenvector centrality) are robust and vary little for different thresholds, others (betweenness) are moderately robust, and again others (local clustering coefficient) are highly sensitive. The authors conclude that a subset of network metrics yields similar results for a variety of thresholds and recommends the use of these when dealing with this particular type of biological network data.

In order to study the effect of missing data on the quantitative analysis of historical correspondence networks, neither the removal of nodes nor the introduction of thresholds are the most informative ways to consider incomplete networks. Node removal is unlikely to be useful, because large correspondence networks are very likely to contain at least some data for 'popular' nodes - even if their own archives have not been digitised or are not available. An example of this is the archive of John Thurloe, who between 1651 and 1660 was a highly influential figure in Oliver Cromwell's government, and Secretary to the Council of State during the Protectorate. His personal archive has not been added to a centralised repository, yet because letters by him appear in a number of other archives, he nevertheless features in other quantitative correspondence network studies and even ranks highly in some network metrics. Correspondence networks are weighted networks if we regard the number of letters sent from one person to another as a weight of that directed connection. Thresholding may therefore in principle offer some insight into incomplete networks, but it does not represent a particularly realistic representation of the kind of data loss found in historical correspondence archives. In order to model the effect of missing data in historical correspondence networks, then, the sampling methods we employ must emulate the varied reasons why particular letters or letter collections are absent from the historical record.

Networks based on historical correspondence archives have their own patterns of missing data. Often they contain very large numbers of letters between particular pairs of individuals. Missing data will either be the result of the inevitable random loss of individual documents or be of particular events that lead to a more systematic absence: the missing data may consist of entire folios (the large volumes into which correspondence is often bound for preservation) that are missing, or a catalogue of correspondence (here meant as a discrete, self-contained set of correspondences, often containing all the collected letters of a single individual) which has not been digitised yet. If large numbers of letters are destroyed on purpose, this will likely happen in a systematic way. If a person or an institution archives their correspondence in date order in boxes or folios, entire blocks of years might be lost, rather than just a random set of letters. In other cases, letters or catalogues may be added to the existing archive, which raises the question of how much we should infer from existing archives, given that more data may be added in the future.

This paper takes various likely patterns of 'missingness' into account, and models missing nodes, letters, folios, and catalogues. Unlike social network data, calculating missing historical correspondence data cannot be done by inferring completeness from the 'response rate' of a survey, but rather must work on the assumption that the correspondence we have is incomplete, and a subset from a much larger body. In some cases, historical network data has been inferred using statistical text mining of biographical source material, and is therefore inherently probabilistic. The project mentioned above, Six Degrees of Francis Bacon, uses the co-occurence of individuals in ODNB entries to infer relationships between historical actors, and as such is likely to be missing many ties as well as inferring some relationships that did not in fact exist.

As discussed above, historical network data is at the mercy of collection, archival and digitisation practices, and as such its 'missingness' has a particular structure. Historical correspondence networks may be incomplete because individual letters have been lost, because entire folios or even catalogues have not been digitised, or because whole years of material are absent, having been destroyed or never been archived as a result of of revolutions, wars, or sieges. Sometimes political disruption is the catalyst for a transfer rather than an absence in archives. Correspondence held by the Bodleian between 1644---1649, and forming the Bodleian card catalogue data used here, contains substantial correspondence for the Civil War period which otherwise would have likely ended up in the State Papers. This paper attempts to reflect the effect of these historical contingencies by simulating the removal of data along these categories through sampling methods that mirror the different types of absences found in our data. We find that in large historical correspondence datasets the robustness of many widely used network measures is high even when large random samples are removed, and that these results are largely independent of the specific type of sampling.

# Method

## Datasets

We study three large early modern historical correspondence networks, which rely on three collections that were amassed in very different ways, and for very different reasons. The first of these, Early Modern Letters Online (EMLO), is a collection of individual catalogues of correspondence—currently 135 in total—contributed to EMLO by hundreds of academic scholars over the past twelve years.[^2] Most of these are the correspondence of a single individual, with one major exception, the Bodleian card catalogue (BCC), which we separate out, as a second dataset. This card catalogue was the product of work by two twentieth-century employees and one volunteer in the Bodleian and ultimately based on individual and idiosyncratic acquisitions by the Library over time, resulting in an 'ad hoc' and 'iterative' set of metadata. [@lewis_ghosts_2013] EMLO and the BCC span almost four centuries of European history between 1500 and 1900, but most of the data in EMLO covers the seventeenth and eighteenth centuries, and British and Dutch diplomatic and intellectual history in particular. Our third dataset is the State Papers of the Stuart period of British history (1603-1714), derived from the nineteenth century catalogues (called 'calendars') of the collection, which were digitised by the company Gale. The State Paper Office was established in 1610 with the aim of collecting the English State's private and working manuscripts in a single place, and was to become the principal archive and working library for the parliamentary executive, while essentially being the private papers of the monarch [For accounts of the organisation of the State Paper Office see @hunt2018]. We might therefore expect this 'official' record of the English State to present a more unified or coherent worldview than EMLO. In fact, the State Papers are also full of partial or shifting perspectives: individual secretaries often viewed their official documents as 'private' and kept them as their possessions on leaving office.

[^2]: See <http://emlo-portal.bodleian.ox.ac.uk/collections/?page_id=2259> for a full list of contributors and http://emlo-portal.bodleian.ox.ac.uk/collections/?page_id=1966 for the current list of EMLO catalogues.

Together, these represent about 320,000 individual pieces of correspondence, and 60,000 individuals, spread over a timespan of four hundred years (table \@ref(tab:networkTable)). Both EMLO and SPO have had extensive reconciliation and disambiguation carried out: The Networking Archives project team uses a custom-designed 'disambiguation engine' for the State Papers, built as an aid to manual disambiguation. With the help of this tool and two years of work by team members, more than 54,000 name strings have been reduced to 30,000. All letters added to EMLO are processed through EMLO Recon - bespoke software which suggests matches to existing people records in the dataset.

Despite this work, and the size of the datasets, both EMLO and SPO should be considered partial. State Papers Online, for example, contains very little from the State Papers: Foreign series past 1660, and the number of documents for the years of the English Civil Wars (1642-1651) are minimal, as Charles II left London and moved the centre of his administration to Oxford and York. In other cases data is 'missing' even though it has survived, because it has not yet been digitised. The catalogue of Johan de Witt, though one of the largest in EMLO, is still embryonic and is currently only one-fifth of his total surviving correspondence. [^3] In other cases, such as that of Jan Comenius, mentioned in the introduction, the majority of an archive has been destroyed and will never be recovered. The correspondence data may be imbalanced, too: archives, historically, are usually a collection of an individual or family's incoming letters. Where large numbers of outgoing letters are found in a catalogue, it is usually the result of a modern effort to 'reassemble' a single individual's correspondence. A large connected dataset such as EMLO mitigates this imbalance to a certain extent, as letters sent by one individual may be found in letters received of another, but it is another source of data 'loss' to be noted.

[^3]: see <http://emlo-portal.bodleian.ox.ac.uk/collections/?catalogue=johan-de-witt>

For the purposes of the experiments carried out in this article, as well as on the *Networking Archives* project more generally, all three of these datasets were converted into directed, unweighted networks, with each author/recipient pair represented as an edge. Letters with multiple authors and recipients were separated out into multiple edges. Though the archives often contain many multiples of letters between pairs of authors and recipients, the use of unweighted networks was a deliberate choice: based on the assumption that rankings which depend on the existence of an edge rather than its strength are less susceptible to error in the case of missing letters. Though a study of weighted network robustness would likely be informative, it is outside of the scope of this paper.

```{r message=FALSE, warning=FALSE, include=FALSE}
library(kableExtra)

library(tidyverse)
library(tidygraph)
library(igraph)
library(DT)
library(ggraph)
library(snakecase)
library(lubridate)
library(cowplot)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
location <- read_csv("~/Downloads/EMLO/location.csv", col_types = cols(.default = "c"))
person <- read_csv("~/Downloads/EMLO/person.csv")
work <- read_csv("~/Downloads/EMLO/work.csv", col_types = cols(.default = "c"))

colnames(location) = to_snake_case(colnames(location))
colnames(person) = to_snake_case(colnames(person))
colnames(work) = to_snake_case(colnames(work))
```

```{r message=FALSE, warning=FALSE, include=FALSE}
network = read_delim('/Users/Yann/Documents/non-Github/na_intersecting_chapter/overlaps/emlo_full_network.dat', delim = '\t', col_names = F)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
emlo_dupes = read_delim('/Users/Yann/Documents/non-Github/na_chapter_1/emlo_dupes.csv', delim = ';', col_names = F)

emlo_dupes_to_remove = c(emlo_dupes$X2,emlo_dupes$X3, emlo_dupes$X4) %>% as_tibble() %>% mutate(value = trimws(value)) %>% filter(!is.na(value)) %>% pull(value)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
abstract_same_dupes = work %>% 
  filter(standard_gregorian_date>'1590-01-01') %>% 
  filter(standard_gregorian_date<'1720-01-01') %>%
  group_by(standard_gregorian_date, author_emlo_id, recipient_emlo_id, abstract) %>% 
  filter(!is.na(abstract)) %>%
  filter(str_count(abstract) > 20) %>%
  add_tally() %>% 
  filter(n!=1) %>% 
  arrange(standard_gregorian_date) %>%
  distinct(standard_gregorian_date, author_emlo_id, recipient_emlo_id, abstract, .keep_all = T) %>%  
  pull(emlo_letter_id_number)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
possible_dupes = work %>% 
  filter(standard_gregorian_date>'1590-01-01') %>% 
  filter(standard_gregorian_date<'1720-01-01') %>%
  filter(!emlo_letter_id_number %in% emlo_dupes_to_remove) %>% 
  filter(!emlo_letter_id_number %in% abstract_same_dupes)%>%
  group_by(standard_gregorian_date, author_emlo_id, recipient_emlo_id) %>% 
  add_tally() %>% 
  filter(n!=1) %>% 
  filter(n<4) %>% group_by(standard_gregorian_date, author_emlo_id, recipient_emlo_id) %>% 
  summarise(all_cats = paste0(original_catalogue_name, collapse = ';'), emlo_letter_id_number) %>% separate(all_cats, into = c('cat1', 'cat2', 'cat3', 'cat4'), sep = ';') %>% filter(cat1 != cat2) %>%
  arrange(standard_gregorian_date) %>% 
  distinct(author_emlo_id, recipient_emlo_id, standard_gregorian_date, .keep_all = T) %>% 
  pull(emlo_letter_id_number)

bcc_poss_dupes = work %>% 
  filter(emlo_letter_id_number %in% possible_dupes) %>% 
  filter(original_catalogue_name == 'Bodleian card catalogue') %>% pull(emlo_letter_id_number)
```

```{r message=FALSE, warning=FALSE, include=FALSE}

unknowns = person %>% filter(str_detect(person_primary_name_in_emlo,'(?i)unknown') |str_detect(person_primary_name_in_emlo,'(?i)unidentified') ) %>% pull(emlo_person_id)

unknown_letters = work %>% filter(author_emlo_id %in% unknowns | recipient_emlo_id %in% unknowns) %>% pull(emlo_letter_id_number)

unknowns = c(unknowns,c('903934','23155', '6854', '853', '923980', '270', '300827', '901925', '906141'))
```

```{r message=FALSE, warning=FALSE, include=FALSE}

emlo_letters = work %>% filter(original_catalogue_name != 'Bodleian card catalogue') %>% pull(emlo_letter_id_number)
bcc_letters = work %>% filter(original_catalogue_name == 'Bodleian card catalogue') %>% pull(emlo_letter_id_number)

 emlo_network_filtered = network %>% filter(! X5 %in% possible_dupes) %>% 
   filter(X5 %in% emlo_letters) %>% 
  filter(!X5 %in% emlo_dupes_to_remove) %>% 
  filter(! X5 %in% unknown_letters) %>% 
  filter(! X5 %in% abstract_same_dupes) 

 bcc_network_filtered = network %>% filter(! X5 %in% possible_dupes) %>% 
   filter(X5 %in% bcc_letters) %>% 
  filter(!X5 %in% emlo_dupes_to_remove) %>% 
  filter(! X5 %in% unknown_letters) %>% 
  filter(! X5 %in% abstract_same_dupes) 
```

```{r message=FALSE, warning=FALSE, include=FALSE}

emlo_letters = work %>% filter(original_catalogue_name != 'Bodleian card catalogue') %>% pull(emlo_letter_id_number)

bcc_letters = work %>% filter(original_catalogue_name == 'Bodleian card catalogue') %>% pull(emlo_letter_id_number)

emlo_total_letters = work %>% filter(original_catalogue_name != 'Bodleian card catalogue') %>% tally() %>% pull(n)

bcc_total_letters = work %>% filter(original_catalogue_name == 'Bodleian card catalogue') %>% tally() %>% pull(n)

emlo_date_range_min = work %>% mutate(year_date = as.numeric(year_date)) %>% filter(!is.na(year_date)) %>% filter(year_date<2000) %>% filter(year_date>1000) %>% filter(original_catalogue_name != 'Bodleian card catalogue') %>% pull(year_date) %>% min()

emlo_date_range_max = work %>% mutate(year_date = as.numeric(year_date)) %>% filter(!is.na(year_date)) %>% filter(year_date<2000) %>% filter(year_date>1000) %>% filter(original_catalogue_name != 'Bodleian card catalogue') %>% pull(year_date) %>% max()

bcc_date_range_min = work %>% mutate(year_date = as.numeric(year_date)) %>% filter(!is.na(year_date)) %>% filter(year_date<2000) %>% filter(year_date>1000) %>% filter(original_catalogue_name == 'Bodleian card catalogue') %>% pull(year_date) %>% min()

bcc_date_range_max = work %>% mutate(year_date = as.numeric(year_date)) %>% filter(!is.na(year_date)) %>% filter(year_date<2000) %>% filter(year_date>1000) %>% filter(original_catalogue_name == 'Bodleian card catalogue') %>% pull(year_date) %>% max()

emlo_nodes = network %>% filter(X5 %in% emlo_letters) %>% distinct(X1, X2) %>% graph_from_data_frame() %>% gorder()

emlo_edges = network %>% filter(X5 %in% emlo_letters) %>% distinct(X1, X2) %>% graph_from_data_frame()%>% gsize()

bcc_nodes = network %>% filter(X5 %in% bcc_letters) %>% distinct(X1, X2) %>% graph_from_data_frame() %>% gorder()

bcc_edges = network %>% filter(X5 %in% bcc_letters) %>% distinct(X1, X2) %>% graph_from_data_frame()%>% gsize()



emlo_diameter = work %>% filter(original_catalogue_name != 'Bodleian card catalogue') %>% distinct(author_emlo_id, recipient_emlo_id) %>% graph_from_data_frame() %>% diameter()

emlo_avg_path = work %>% filter(original_catalogue_name != 'Bodleian card catalogue') %>% distinct(author_emlo_id, recipient_emlo_id) %>% graph_from_data_frame() %>% average.path.length()

bcc_diameter = work %>% filter(original_catalogue_name == 'Bodleian card catalogue') %>% distinct(author_emlo_id, recipient_emlo_id) %>% graph_from_data_frame() %>% diameter()

bcc_avg_path = work %>% filter(original_catalogue_name == 'Bodleian card catalogue') %>% distinct(author_emlo_id, recipient_emlo_id) %>% graph_from_data_frame() %>% average.path.length()

emlo_global_cluster = work %>% filter(original_catalogue_name != 'Bodleian card catalogue') %>% distinct(author_emlo_id, recipient_emlo_id) %>% graph_from_data_frame() %>% igraph::transitivity(type = 'globalundirected')

bcc_global_cluster = work %>% filter(original_catalogue_name == 'Bodleian card catalogue') %>% distinct(author_emlo_id, recipient_emlo_id) %>% graph_from_data_frame() %>% igraph::transitivity(type = 'globalundirected')

```

```{r message=FALSE, warning=FALSE, include=FALSE}
spo_raw = read_delim('fromto_all_place_mapped_stuart_sorted', delim = '\t', col_names = F )

spo_network_filtered = spo_raw %>% dplyr::select(X1, X2, X3, X8, X5) %>% mutate(X8 = str_remove(X8, "\\sf\\.[0-9]{1,}"))
```

```{r message=FALSE, warning=FALSE, include=FALSE}
spo_total_letters = spo_network_filtered %>% distinct(X5) %>%  tally() %>% pull(n)

spo_date_range_min = spo_network_filtered %>% mutate(year = year(ymd(X3))) %>% filter(year >1400) %>%  pull(year) %>% min()

spo_date_range_max = spo_network_filtered %>% mutate(year = year(ymd(X3)))  %>% filter(year <1900)%>% pull(year) %>% max()

spo_nodes = spo_network_filtered %>% distinct(X1, X2) %>% graph_from_data_frame() %>% gorder()

spo_edges = spo_network_filtered %>% distinct(X1, X2) %>% graph_from_data_frame() %>% gsize()

spo_diameter =  spo_network_filtered %>% distinct(X1, X2) %>% graph_from_data_frame() %>% diameter()

spo_avg_path =  spo_network_filtered %>% distinct(X1, X2) %>% graph_from_data_frame() %>% average.path.length()

spo_global_cluster = spo_network_filtered %>% distinct(X1, X2) %>% graph_from_data_frame() %>% igraph::transitivity(type = 'globalundirected')
```

```{r networkTable, echo=FALSE, message=FALSE, warning=FALSE}
library(reshape2)
options(scipen = 999999)
df = data_frame(' ' = c('Letter Records' ,
                    'Nodes' , 
                    'Unique Edges' , 
                    paste0('Diameter' , footnote_marker_symbol(1, 'latex')),
                    'Avg path length' , 
                    'Clustering Coefficient',
                    'Earliest date', 
                    'Latest date' ), EMLO = c('Letters' = prettyNum(emlo_total_letters, big.mark = ','),
                    'Nodes' = prettyNum(emlo_nodes, big.mark = ','), 
                    'Unique Edges' = prettyNum(emlo_edges, big.mark = ','), 
                    'Diameter' = emlo_diameter, 
                    'Avg path length' = round(emlo_avg_path,2),
                    'Clustering Coefficient' = round(emlo_global_cluster,5),
                    'Earliest date' = emlo_date_range_min, 
                    'Latest date' = emlo_date_range_max), 
           BCC = c(prettyNum(bcc_total_letters, big.mark = ','),
                   prettyNum(bcc_nodes, big.mark = ','), 
                   prettyNum(bcc_edges, big.mark = ','), 
                   bcc_diameter, 
                   round(bcc_avg_path,2),
                   round(bcc_global_cluster,5),
                   bcc_date_range_min,
                   bcc_date_range_max), 
           SPO = c(prettyNum(spo_total_letters, big.mark = ','),
                   prettyNum(spo_nodes, big.mark = ','), 
                   prettyNum(spo_edges, big.mark = ','), 
                   spo_diameter, 
                   round(spo_avg_path,2), 
                   round(spo_global_cluster,5),
                   spo_date_range_min, 
                   spo_date_range_max)) %>% mutate(EMLO = as.character(EMLO)) %>% mutate(BCC = as.character(BCC)) %>% mutate(SPO = as.character(SPO)) %>% t() %>% as_tibble() 

colnames(df) <- df[1,]
df <- df[-1, ] 

  df %>% mutate(' ' = c('EMLO', 'BCC', 'SPO' )) %>% 
    select(` `, everything()) %>% 
    pivot_longer(names_to = 'inst', values_to = 'value', cols = 2:9) %>% pivot_wider(names_from = 1, values_from = value) %>% rename(' ' = inst) %>%
    kable(booktabs = T,
             caption = "Network Summaries", escape = F) %>% 
  kable_styling(latex_options = c("striped"), position = "right") %>% 
    footnote(symbol = c('Global metrics were calculated on an undirected version of each network'))
```

Despite their different origins, the datasets exhibit some surprising similarities. The distribution of the number of connections, or 'degree distribution', follows a similar pattern in all three, which can be described by a power law, indicated by a straight line when plotted on a double logarithmic scale (figure \@ref(fig:degreeDist)). The networks are said, then, to be 'scale free': meaning that a similar pattern, of a small number of highly-connected nodes and a large number of nodes with very few connections, can be observed in any given sub-section of the network. The implications of scale-free networks have been discussed at length elsewhere, but this structure is also important for understanding the ways in which different categories of measures are affected by missing data. [see @barabasi_emergence_1999; @strogatz_collective_1998 for foundational discussion of scale-free networks.]

```{r degreeDist, echo=FALSE, message=FALSE, warning=FALSE, fig.cap = "Degree distribution plot for each of the networks. The downward-sloping diagonal line on a log-log axis plot is an indication that the networks are scale-free.", fig.height=2.5, fig.width=6}
emlo_network_filtered %>% 
  distinct(X1, X2) %>% 
  graph_from_data_frame() %>% 
  as_tbl_graph() %>% 
  mutate(degree = centrality_degree(mode = 'total')) %>% 
  as_tibble() %>% 
  group_by(degree) %>% 
  tally() %>% 
  mutate(dataset = 'EMLO') %>% 
  rbind(bcc_network_filtered %>% 
          distinct(X1, X2) %>% 
          graph_from_data_frame() %>% 
          as_tbl_graph() %>% 
          mutate(degree = centrality_degree(mode = 'total')) %>%
          as_tibble() %>% 
          group_by(degree) %>% 
          tally() %>% 
          mutate(dataset = 'BCC')) %>% 
  rbind(spo_network_filtered %>% 
          distinct(X1, X2) %>% 
          graph_from_data_frame() %>% 
          as_tbl_graph() %>% 
          mutate(degree = centrality_degree(mode = 'total')) %>% 
          as_tibble() %>% 
          group_by(degree) %>% 
          tally() %>% 
          mutate(dataset = 'SPO')) %>% 
  ggplot() + 
  geom_point(aes(x = degree, y = n)) + 
  scale_x_log10() + 
  scale_y_log10() + 
  facet_wrap(~dataset, ncol = 3) + 
  theme_bw() + 
  theme(text = element_text(family = 'Times')) +
  labs(y = 'Count', x = 'Degree')



```

## Sampling techniques

For each of the three networks, we created subsamples of the network by removing a) letters, b) nodes, c) years, d) folios, and e) entire correspondence catalogues, reflecting common forms of absences in the historical record, as discussed above. An exception to this was the final experiment, which simulated another likely source of data error, that brought about by spelling error and variants, done by reverting random names in the data to their uncleaned state. In all cases we removed a particular portion of the entity in question, e.g. 10% of letters, or 30% of catalogues, rounding up where necessary. In the first five cases, the samples were produced in 1% steps, from 99% to 1% of data remaining, and in the final experiment simulating disambiugation errors, steps of 10% were used to reduce the much more considerable computatation time. As the volume of correspondence for individual years and in individual folios and catalogues varies considerably we expected larger fluctuations between samples in these cases than when removing a randomly selected set of individual letters.

Next, we compared the values of a set of standard metrics (total degree, betweenness centrality, eigenvector centrality, closeness centrality, and transitivity) in the full network to the equivalent values in the sampled networks for each node, disregarding any nodes that did not appear in the sample, similar to previous approaches in the literature. [@galaskiewicz_estimating_1991; @costenbader_stability_2003; @borgatti_robustness_2006; @smith_network_2017; @noauthor_network_nodate] To compare the values we used Spearman's rank correlation (referred to $\rho$ hereafter), because rankings are a more useful way for interpreting network metrics in many contexts, as absolute values may a) fluctuate due to larger historical developments and changes in archival practice, and b) are difficult to interpret in the case of betweenness centrality, closeness centrality, and eigenvector centrality, because the absolute values for the highest-ranking nodes can be orders of magnitude larger than the lowest-ranking for these measurements. In all cases, the relationship between the original and sample values is monotonic and therefore appropriate for a Spearman's rank correlation. We collected 100 independent samples at each 1% interval, from 99% to 1% of the full network, for each category of removed entity (letter, folio, year, catalogue, and node). This process was repeated forty times to get a realistic average value and to measure variability. In other words, we simulated progressively increasing amounts of missing data, and measured how this affected quantitative results.

# Results

We find that the measures are remarkably robust to many types of data removal, across all of the networks. The figures 3 to 7 below display some of the key findings, and full results are available in the appendix, and in summarised form in table \@ref(tab:summaryTable). In each case we display the changes in correlation as larger parts of the network are removed as well as the variability of that change. The former is visualised in the charts below as a single blue line, representing the mean correlation for each sample (from 99% to 1%) and the latter is measured as the standard deviation of the forty observations for each sample, visualised as a gray shaded area. In general, most Spearman correlations remained high (many with a $\rho$ above 0.7) until 50% of the network was removed. Some metrics and sampling methods showed more variability than others, which is shown here through the standard deviation: for example, sampling catalogues resulted in high variance (a standard deviation of 0.328, where the possible values ranged from -1 to +1), and to a lesser extent, sampling years and nodes did too. Most network measures were robust to letter removal, and showed very little variability. This may be because of the particular structure of historical correspondence networks. In general, many connections between pairs of individuals will be marked by many letters, written over a number of years. This means that the most prominent connections in the network are also the most robust ones with regard to letter removal. Node removal produced similar results, though it resulted in more variation in measures that are calculated by using the entire network (closeness and eigenvector centralities). Surprisingly, even removing entire catalogues---essentially removing at random some of the top-scoring degree nodes---had little effect on the degree of the remaining nodes though it did have a more substantial impact on closeness and eigenvector centralities. We find that one metric, local clustering, or transitivity, is consistently sensitive to the removal of any type of data. This highlights that some research questions will be affected by incompleteness much more than others. It also underlines how remarkably robust most metrics actually are: the sensitivity of local clustering is the sensitivity that skeptics of quantitative analysis might expect to see across the board. We find that it is the exception that proves the rule, as local clustering demonstrates that some network metrics *may* be very sensitive to data removal, but most are *not*.

```{r message=FALSE, warning=FALSE, include=FALSE}

load('robustness_results')

```

```{r summaryTable, echo=FALSE, message=FALSE, warning=FALSE}
robustness_results %>% 
  #filter(dataset == 'emlo') %>%
  rename(variable = type, value = cor, percent_out = sample) %>% 
  mutate(metric = ifelse(metric == 'degree', 'degree_total', metric)) %>% 
  mutate(metric = ifelse(metric == 'closeness', 'close', metric)) %>%
  mutate(percent_out = as.numeric(percent_out)) %>% 
    filter(percent_out %in% c(50, 90)) %>%
    mutate(variable = ifelse(variable == 'letter_id', 'letter',
                             ifelse(variable == 'folio_or_catalogue', 'catalogue', 
                                    ifelse(variable == 'year_date', 'year', variable)))) %>% 
  rename(`Removal Type` = variable) %>% 
  group_by(metric,  `Removal Type`, percent_out) %>% 
  summarise(mean = round(mean(value),3), 
            standard_dev = round(sd(value, na.rm = T), 3)) %>% 
  ungroup() %>% 
 # select(-dataset) %>% 
  mutate(metric = ifelse(metric == 'betweenness', 'Betweenness Centrality',
                         ifelse(metric == 'close', 'Closeness Centrality',
                                ifelse(metric == 'degree_in', 'In-Degree',
                                       ifelse(metric == 'degree_out', 'Out-Degree',
                                              ifelse(metric == 'degree_total', 'Total Degree',
                                                     ifelse(metric == 'eigen', 'Eigenvector Centrality',
                                                            ifelse(metric == 'transitivity', 'Local Clustering Coefficient', metric)))))))) %>% 
  mutate(metric = ifelse(metric == 'Betweenness Centrality' & percent_out == 50, paste0(metric, footnote_marker_symbol(2)), metric)) %>%
  pivot_wider(names_from = `Removal Type`, values_from = c(mean, standard_dev)) %>% 
  select(metric, `removed` = percent_out, mean_catalogue, standard_dev_catalogue, mean_letter, standard_dev_letter, mean_nodes, standard_dev_nodes, mean_year, standard_dev_year) %>%
  kbl(escape = F, booktabs = T, col.names = c('', 'Portion removed', 'Mean $\\rho$', paste0('SD',footnote_marker_symbol(1)), 'Mean $\\rho$', 'SD', 'Mean $\\rho$', 'SD', 'Mean $\\rho$', 'SD'), caption = "Summary statistics for the removal correlations at fifty and ninety percent removed, showing the mean Spearman's rho ($\\rho$) and standard deviation across forty iterations.") %>% 
  add_header_above(c(" " = 2, "Catalogues" = 2, "Letters" = 2, "Nodes" = 2, "Years" = 2)) %>% 
  kable_styling(latex_options = c("striped", 'scale_down')) %>% footnote(symbol = c('Standard deviation', 'Explanations of this and other standard network terms can be found in a glossary at the end of this article.'))
```

## Letter Removal

Letter removal had surprisingly little effect on any of our three networks - the correlations stayed high ($\rho$ above 0.6 in all three datasets) even when just 10% of the total letters remained, and the variation between random samples was low (figure \@ref(fig:lettersRemoval)). This is probably because of the aforementioned nature of correspondence data, in which many network edges are marked repeatedly, by many letters. Removing random letters when there are large numbers of them between two people makes it very unlikely the corresponding network edge disappears completely. There were some subtle differences between the metrics, in two broad patterns: some measurements, chiefly degree and betweenness centrality, became less correlated in an almost linear fashion as progressively larger parts of the network were removed, whereas eigenvector centrality showed very little difference until most of the network was removed, at which point it dropped substantially. In all cases, the standard deviation was small: the values generated by each iteration stayed very close to the mean.

```{r lettersRemoval, echo=FALSE, message=FALSE, warning=FALSE, fig.align= 'center', fig.width = 6, fig.height=4, fig.cap="Robustness of Key Measures to Letter Removal. The blue line indicates the mean Spearman correlation ($\\rho$) mean across all forty iterations. The standard deviation at each sample is represented as a shaded gray area, however it is usually not visible in this mode of removal because the variation between iterations was so small. Full results are in the appendix."}
robustness_results %>% 
 # filter(dataset == 'emlo') %>% 
  mutate(metric = ifelse(metric == 'degree' | metric == 'degree_total', 'Degree', metric)) %>%
  mutate(metric = ifelse(metric == 'eigen', 'Eigenvector', metric)) %>%
  mutate(metric = ifelse(metric == 'transitivity', 'Transitivity', metric)) %>% 
  mutate(metric = ifelse(metric == 'closeness', 'Closeness', metric))%>% 
  mutate(metric = ifelse(metric == 'betweenness', 'Betweenness', metric)) %>%
  mutate(sample = as.numeric(sample)) %>% 
  rename(variable = type) %>% 
    mutate(variable = ifelse(variable == 'letter_id', 'letter',
                             ifelse(variable == 'folio_or_catalogue', 'catalogue', 
                                    ifelse(variable == 'year_date', 'year', variable)))) %>% 
  mutate(dataset = ifelse(dataset == 'emlo', 'EMLO',
                          ifelse(dataset == 'bcc', 'BCC', 'SPO')))%>% 
  rename(`Removal Type` = variable) %>%
  filter(`Removal Type` == 'letter') %>% 
  filter(metric %in% c('Degree', 'Eigenvector', 'Transitivity','Betweenness')) %>%  
  group_by(metric, dataset, `Removal Type`, sample) %>% 
  summarise(mean = mean(cor), min = min(cor), max = max(cor),sd = sd(cor)) %>% 
  ggplot() + 
  geom_ribbon(aes(x = sample, ymax = mean+sd, ymin = mean-sd), alpha = .6, fill = 'gray75')  + 
   geom_line(aes(x = sample, y = mean), alpha = .8, color = 'blue') +
  labs(x = 'Percentage Removed (letters)', y = expression(rho*" (mean)")) + 
  theme_bw() +
  coord_fixed(100,ylim = c(0,1)) + 
  facet_grid(dataset~metric) + 
  scale_color_viridis_d()  +
  scale_y_continuous(breaks = c(.5, 1)) +
  scale_x_continuous(breaks = c(50, 100)) + 
  theme(panel.grid.minor =element_blank(), 
        strip.text = element_text(size = 11), 
        text = element_text(family = 'Times'))

```

## Node Removal

We assume that this method of data removal for historical networks is the least reflective of real-world missing historical data---most of the 'important' actors within the networks are found across a number of archives, and it is unlikely (though not impossible, in some historical contexts) that an individual would be systematically erased across all archives, as both a sender and recipient of letters. There is existing literature which looks at the global tolerance of scale-free networks to both random error and coordinated attack, concluding that networks are robust to the former but vulnerable to the latter.[see @albert_error_2000; @holme_attack_2002; @jeong_lethality_2001] This may partially explain why when random nodes are removed the individual network metrics are also resilient. Degree and betweenness sensitivity to node removal are very similar to the case of letter removal, with subtle differences. Node removal correlations are very high ($\rho$ above 0.8) until 70% of the network remains, and then decline more sharply than with letter removal (figure \@ref(fig:nodesRemoval)). For closeness and eigenvector centrality, there is much more variation in the sensitivity across each iteration, as increasing portions of the network are removed. This may be because eigenvector and closeness centrality are more dependent on high-degree nodes, which are removed in larger numbers in these simulations than when letters are removed. The variation in eigenvector centrality scores is particularly striking for the BCC and EMLO networks, but less so for SPO.

```{r nodesRemoval, echo=FALSE, message=FALSE, warning=FALSE, fig.align= 'center', fig.width = 6, fig.height=4,fig.cap="Robustness of Measures to Node Removal. The blue line indicates the mean Spearman correlation ($\\rho$) across forty iterations. The standard deviation at each sample is represented as a shaded gray area. Generally, correlations remained high until 70\\% of the network was removed and then declined sharply. Degree and betweeness sensitivity were similar to letter removal but closeness (not shown) and eigenvector centralities displayed more variation. Full results in the appendix."}
robustness_results %>% 
 # filter(dataset == 'emlo') %>% 
  mutate(metric = ifelse(metric == 'degree' | metric == 'degree_total', 'Degree', metric)) %>%
  mutate(metric = ifelse(metric == 'eigen', 'Eigenvector', metric)) %>%
  mutate(metric = ifelse(metric == 'transitivity', 'Transitivity', metric)) %>% 
  mutate(metric = ifelse(metric == 'closeness', 'Closeness', metric))%>% 
  mutate(metric = ifelse(metric == 'betweenness', 'Betweenness', metric)) %>%
  mutate(sample = as.numeric(sample)) %>% 
  rename(variable = type) %>% 
    mutate(variable = ifelse(variable == 'letter_id', 'letter',
                             ifelse(variable == 'folio_or_catalogue', 'catalogue', 
                                    ifelse(variable == 'year_date', 'year', variable)))) %>% 
  mutate(dataset = ifelse(dataset == 'emlo', 'EMLO',
                          ifelse(dataset == 'bcc', 'BCC', 'SPO')))%>% 
  rename(`Removal Type` = variable) %>%
  filter(`Removal Type` == 'nodes') %>% 
  filter(metric %in% c('Degree', 'Eigenvector', 'Transitivity','Betweenness')) %>%  
  group_by(metric, dataset, `Removal Type`, sample) %>% 
  summarise(mean = mean(cor), min = min(cor), max = max(cor),sd = sd(cor)) %>% 
  ggplot() + 
  geom_ribbon(aes(x = sample, ymax = mean+sd, ymin = mean-sd), alpha = .6, fill = 'gray75')  + 
   geom_line(aes(x = sample, y = mean), alpha = .8, color = 'blue') +
  labs(x = 'Percentage Removed (nodes)', y = expression(rho*" (mean)")) + 
  theme_bw() +
  coord_fixed(100,ylim = c(0,1)) + 
  facet_grid(dataset~metric) + 
  scale_color_viridis_d()  +
  scale_y_continuous(breaks = c(.5, 1)) +
  scale_x_continuous(breaks = c(50, 100)) + 
  theme(panel.grid.minor =element_blank(), 
        strip.text = element_text(size = 11), 
        text = element_text(family = 'Times'))



```

## Catalogue removal

One of the three archives studied here, EMLO, is divided into individual catalogues.^[The EMLO catalogues are modern subsets, based on reassembled letters of a single individual (often ultimately from on a printed edition but not in all cases). On the other hand, the mass of SPO data has been reorganised over time, now mostly into 'series' and 'classes', based on either geography or periods of rule rather than individuals. There are a small number of additional individual-based collections, such as the Cecil Papers, which would be broadly comparable to an EMLO catalogue, but most of the records are not organised in this way.] Each of these catalogues is generally the correspondence of a single individual, often collected by an individual scholar. Because EMLO is organised, and new data is added to it, at a catalogue level, removing varying numbers of these catalogues may provide a realistic simulation of the impact of non-random missing (or added) data on historical scholarship. A common concern in historical network research is that a) any historical correspondence record is inevitably highly incomplete, and b) that many of the records that do survive have not yet been digitised, or even archived. In addition, the ongoing digitisation efforts mean that any analysed dataset will change over time as more correspondence is added to the digital archives. The question whether quantitative results obtained with current data will still hold after these future additions is therefore a further concern. The removal of catalogues can be used to examine the validity of the above concerns. While the results reveal larger variation between the independent simulations (due to the broad distribution of catalogue sizes), all network metrics are remarkably robust up to 50% of removed catalogues ($\rho$ above 0.8 in all cases except transivity and betweenness centrality) and on average not much less robust than for letter or node removal even for 90% of removed catalogues (though in some simulations the correlation plummets for this percentage).

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align= 'center', fig.width = 6, fig.height=2,fig.cap="Robustness of Measures to Catalogue Removal in EMLO dataset. Only EMLO has the catalogue as an organisational unit and so is displayed separately here. Removing full catalogues still did not have a large effect on correlations, though more variation between iterations was displayed - most likely because catalogue vary by size.  The blue line indicates the mean Spearman correlation ($\\rho$) across all forty iterations. The standard deviation at each sample is represented as a shaded gray area. Full results in the appendix."}
robustness_results %>% 
  filter(dataset == 'emlo') %>% 
  mutate(metric = ifelse(metric == 'degree' | metric == 'degree_total', 'Degree', metric)) %>%
  mutate(metric = ifelse(metric == 'eigen', 'Eigenvector', metric)) %>%
  mutate(metric = ifelse(metric == 'transitivity', 'Transitivity', metric)) %>% 
  mutate(metric = ifelse(metric == 'closeness', 'Closeness', metric))%>% 
  mutate(metric = ifelse(metric == 'betweenness', 'Betweenness', metric)) %>%
  mutate(sample = as.numeric(sample)) %>% 
  rename(variable = type) %>% 
    mutate(variable = ifelse(variable == 'letter_id', 'letter',
                             ifelse(variable == 'folio_or_catalogue', 'catalogue', 
                                    ifelse(variable == 'year_date', 'year', variable)))) %>% 
  mutate(dataset = ifelse(dataset == 'emlo', 'EMLO',
                          ifelse(dataset == 'bcc', 'BCC', 'SPO')))%>% 
  rename(`Removal Type` = variable) %>%
  filter(`Removal Type` == 'catalogue') %>% 
  filter(metric %in% c('Degree', 'Eigenvector', 'Transitivity','Betweenness')) %>%  
  group_by(metric, dataset, `Removal Type`, sample) %>% 
  summarise(mean = mean(cor), min = min(cor), max = max(cor),sd = sd(cor)) %>% 
  ggplot() + 
  geom_ribbon(aes(x = sample, ymax = mean+sd, ymin = mean-sd), alpha = .6, fill = 'gray75')  + 
   geom_line(aes(x = sample, y = mean), alpha = .8, color = 'blue') +
  labs(x = 'Percentage Removed (catalogues)', y = expression(rho*" (mean)")) + 
  theme_bw() +
  coord_fixed(100,ylim = c(0,1)) + 
  facet_grid(dataset~metric) + 
  scale_color_viridis_d()  +
  scale_y_continuous(breaks = c(.5, 1)) +
  scale_x_continuous(breaks = c(50, 100)) + 
  theme(panel.grid.minor =element_blank(), 
        strip.text = element_text(size = 11), 
        text = element_text(family = 'Times'))



```

## Folio Removal

When we think of missing archival data, perhaps the first image that comes to mind is missing folios from shelves - these folios, as material objects, may go missing, be borrowed and not returned, be unavailable for digitisation because of conservation concerns, or destroyed, by accident or deliberately. Two of the archives here are organised by folio. The Bodleian card catalogue data comes from just over 500 individual manuscript folios - each containing anywhere from one to five hundred pieces of correspondence and the State Papers are organised similarly. Our algorithm simulates, essentially, walking the shelves of the archives at random and removing individual manuscript volumes, and calculates the effect on the resulting network measures.

When removing random samples of folios we find similar results to removing letters or nodes, with some results that highlights the organisation of the data. The eigenvector centrality measure of the BCC network shows high variability for random folio removal, which mirrors the pattern for node removal and may suggest that the way in which folios are organised affects the sensitivity of network measurements to random removal. For example, Bodleian card catalogue folios are more likely to contain the correspondence of a single individual, whereas in the State Papers, correspondence for important individuals is spread across a number of volumes. Historical network analysis, then, may be particularly sensitive to folio removal when an archive has been arranged by individual rather than, say, topic or date, though further investigation of this is needed.

```{r folio, echo=FALSE, message=FALSE, warning=FALSE, fig.align= 'center', fig.width = 6, fig.height=3, fig.cap="Folio Removal results for BCC and SPO datasets. Blue line indicates the mean correlation score across all forty iterations. The standard deviation at each sample is represented as a shaded gray area. SPO and BCC include information on the source folio, and we used this as a unit to remove in sampling. Results differed as a result of the type of material collected in these folios: BCC folios are often person-based, and therefore show more variability, whereas SPO folios are often archived by subject or chronologically, and seem to display less variability."}
robustness_results %>% 
  filter(dataset != 'emlo') %>% 
  mutate(metric = ifelse(metric == 'degree' | metric == 'degree_total', 'Degree', metric)) %>%
  mutate(metric = ifelse(metric == 'eigen', 'Eigenvector', metric)) %>%
  mutate(metric = ifelse(metric == 'transitivity', 'Transitivity', metric)) %>% 
  mutate(metric = ifelse(metric == 'closeness', 'Closeness', metric))%>% 
  mutate(metric = ifelse(metric == 'betweenness', 'Betweenness', metric)) %>%
  mutate(sample = as.numeric(sample)) %>% 
  rename(variable = type) %>% 
    mutate(variable = ifelse(variable == 'letter_id', 'letter',
                             ifelse(variable == 'folio_or_catalogue', 'catalogue', 
                                    ifelse(variable == 'year_date', 'year', variable)))) %>% 
  mutate(dataset = ifelse(dataset == 'emlo', 'EMLO',
                          ifelse(dataset == 'bcc', 'BCC', 'SPO')))%>% 
  rename(`Removal Type` = variable) %>%
  filter(`Removal Type` == 'catalogue') %>% 
  filter(metric %in% c('Degree', 'Eigenvector', 'Transitivity','Betweenness')) %>%  
  group_by(metric, dataset, `Removal Type`, sample) %>% 
  summarise(mean = mean(cor), min = min(cor), max = max(cor),sd = sd(cor)) %>% 
  ggplot() + 
  geom_ribbon(aes(x = sample, ymax = mean+sd, ymin = mean-sd), alpha = .6, fill = 'gray75')  + 
   geom_line(aes(x = sample, y = mean), alpha = .8, color = 'blue') +
  labs(x = 'Percentage Removed (folios)', y = expression(rho*" (mean)")) + 
  theme_bw() +
  coord_fixed(100,ylim = c(0,1)) + 
  facet_grid(dataset~metric) + 
  scale_color_viridis_d()  +
  scale_y_continuous(breaks = c(.5, 1)) +
  scale_x_continuous(breaks = c(50, 100)) + 
  theme(panel.grid.minor =element_blank(), 
        strip.text = element_text(size = 11), 
        text = element_text(family = 'Times'))



```

## Year removal

The three sample datasets, as seen in table \@ref(tab:networkTable), span large ranges of dates, sometimes three or four hundred years (though it should be noted that in all cases, the majority of records are found in a more limited timespan). Intuitively, it is entirely plausible that longitudinal historical datasets may be missing single or multiple years of data. EMLO, being a series of curated catalogues, is very much concentrated in a subset of the years it spans, but even a dataset like the State Papers has peaks and troughs across time. Diplomats often travelled for extensive periods of time, resulting in the dispersal of their correspondence. Joseph Williamson, the Under-secretary of State for the Southern Department of England between 1660 and 1674, travelled to Cologne to represent the State at a diplomatic conference for much of 1673 and 1674. Because of this, there is little correspondence involving Williamson for these years, and his dominance of the archive, due to his unprecedented personal effort in maintaining and archiving his working papers when in Whitehall, is such that this means there is a substantial dip in the volume of data during these years. In this case, the 'missing' data is in fact dispersed elsewhere and therefore not a part of the State's archive, but one can imagine a similar scenario where the material could be simply lost. Data for particular years can be missing or relatively sparse for other more drastic reasons. During the English Civil Wars from 1642 to 1651, the complications arising from the split in the State's administration into parliamentary and royalist factions, compounded by the natural chaos of war meant that part of it moved its working papers elsewhere, and for these years again there is a substantial gap in the State Papers correspondence. A similar profile of variability in the volume of letters per year is also found in the EMLO dataset. Despite containing records spanning from approximately 1500 to 1800, the database coverage is uneven: two ten-year periods (1634-1644 and 1664-1673) contain 22.5% of the total volume of letters. Because historical datasets are often longitudinal, ranging over a span of decades or centuries, substantial gaps in the temporal coverage become more likely and might be thought to have a great deal of effect on the resulting network. Results for this type of removed data largely mirror those for letter removal, with more variability for some metrics (as some years contain much more correspondence than others).

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.align= 'center',fig.width = 6, fig.height=4, fig.cap="Robustness of Measures to Year Removal. The blue line indicates the mean Spearman correlation score across all forty iterations. The standard deviation at each sample is represented as a shaded gray area. The results mirrored those of letter removal, with some more variability due to variations in the amount of material per year. Full results in the appendix)"}
robustness_results %>% 
 # filter(dataset == 'emlo') %>% 
  mutate(metric = ifelse(metric == 'degree' | metric == 'degree_total', 'Degree', metric)) %>%
  mutate(metric = ifelse(metric == 'eigen', 'Eigenvector', metric)) %>%
  mutate(metric = ifelse(metric == 'transitivity', 'Transitivity', metric)) %>% 
  mutate(metric = ifelse(metric == 'closeness', 'Closeness', metric))%>% 
  mutate(metric = ifelse(metric == 'betweenness', 'Betweenness', metric)) %>%
  mutate(sample = as.numeric(sample)) %>% 
  rename(variable = type) %>% 
    mutate(variable = ifelse(variable == 'letter_id', 'letter',
                             ifelse(variable == 'folio_or_catalogue', 'catalogue', 
                                    ifelse(variable == 'year_date', 'year', variable)))) %>% 
  mutate(dataset = ifelse(dataset == 'emlo', 'EMLO',
                          ifelse(dataset == 'bcc', 'BCC', 'SPO')))%>% 
  rename(`Removal Type` = variable) %>%
  filter(`Removal Type` == 'year') %>% 
  filter(metric %in% c('Degree', 'Eigenvector', 'Transitivity','Betweenness')) %>%  
  group_by(metric, dataset, `Removal Type`, sample) %>% 
  summarise(mean = mean(cor), min = min(cor), max = max(cor),sd = sd(cor)) %>% 
  ggplot() + 
  geom_ribbon(aes(x = sample, ymax = mean+sd, ymin = mean-sd), alpha = .6, fill = 'gray75')  + 
   geom_line(aes(x = sample, y = mean), alpha = .8, color = 'blue') +
  labs(x = 'Percentage Removed (years)', y = expression(rho*" (mean)")) + 
  theme_bw() +
  coord_fixed(100,ylim = c(0,1)) + 
  facet_grid(dataset~metric) + 
  scale_color_viridis_d()  +
  scale_y_continuous(breaks = c(.5, 1)) +
  scale_x_continuous(breaks = c(50, 100)) + 
  theme(panel.grid.minor =element_blank(), 
        strip.text = element_text(size = 11), 
        text = element_text(family = 'Times'))

```
## Reconcilation and Disambiguation Errors    

Another common source of data error or corruption found in correspondence archives is that which can be attributed to errors in names. Doing network analysis from correspondence relies on individuals with the same name being split where appropriate, and ambiguous or spelling variants being merged in other cases. One of the datasets used here has been cleaned as part of the project from which this work arises. In the process of doing this data cleaning, we kept a log file recording every change made in the process of cleaning and disambiguating the data. In order to test the impact of network analysis on uncleaned or partially-cleaned data, we used the log file to produce versions of the network where increasing random portions of the data had been returned to its uncleaned state, and again ran a series of correlations between the original and sample data network metric ranks. Figure \@ref(fig:disambigResults) (a) shows that the differences between the original and sample are broadly comparable to those found when removing letters: there is little variation between samples, and in most cases the trajectory is linear. 

There was however an interesting difference between in/out degree and total degree scores - the robustness of the latter was slightly but noticeably lower (Figure \@ref(fig:disambigResults) (b)). This is to do with the nature of the uncleaned data and the shape of the State Papers archive and calendars. Much more of the data cleaning carried has been merging variant names rather than splitting common names into multiple. When letters catalogued under a different name are found and merged a master record, they are often either incoming *or* outgoing—for example the master record for William Cecil, 2nd Earl of Salisbury is a mix of incoming and outgoing letters, but those catalogued under his earlier title, Viscount Cranborne, are mostly incoming. The in and out degree changes in rank balance each other out and have less impact in the change in correlation, whereas the change to total degree for master records after data cleaning mostly results in an increase in rank.


```{r disambigResults, echo=FALSE, message=FALSE, warning=FALSE, fig.height=2.5, fig.width=6, fig.cap = "Robustness results from disambiguation error experiment. To calculate the impact of no or unfinished data cleaning, we reverted progressively larger samples of the data to its uncleaned state, using the log files generated by the data cleaning process. Results were similar to other methods of sampling. In (b), a noticeable difference between in/out degree and total degree robustness can be seen. This is because most of the data cleaning is merging, and often the secondary name variants are mostly either in or outgoing letters rather than a balance between the two."}
library(cowplot)
load('samples_x')

a = samples %>% filter(metric %in% c('degree_in', 'degree_out', 'degree_total')) %>% 
  mutate(removed = 1-removed) %>% 
  mutate(removed = as.character(removed)) %>% 
  ggplot() + 
  geom_point(aes(x =removed, 
                   y = cor, color = metric)) +
  coord_cartesian(ylim = c(0.5,1)) + 
  scale_y_continuous(breaks = c(.5, 1))+ 
  theme_bw() +  theme(panel.grid.minor =element_blank(), 
                      strip.text = element_text(size = 11), 
                      text = element_text(family = 'Times'))+ 
  theme(legend.position = 'bottom') + guides(color = guide_legend(nrow = 2))

b = samples %>% 
  mutate(removed = 1-removed) %>% 
  mutate(removed = as.character(removed)) %>% 
  ggplot() + 
  geom_boxplot(aes(x =removed, 
                   y = cor, group = NULL), alpha = .4)+
  coord_cartesian(ylim = c(0,1)) + 
  scale_y_continuous(breaks = c(.5, 1))+ 
  theme_bw() +  theme(panel.grid.minor =element_blank(), 
                      strip.text = element_text(size = 11), 
                      text = element_text(family = 'Times', size = 8)) + 
  facet_wrap(~metric) 



plot_grid(b,a, nrow = 1, labels = c('(a)', '(b)'), 
          label_fontfamily = 'Times', rel_widths = c(.6, .4),
  label_size = 12, hjust = 0)

```


# Effect on real-world results

```{r message=FALSE, warning=FALSE, cache=TRUE, include=FALSE}
# network_filtered_f = spo_raw %>% 
#   dplyr::select(X1, X2, X3, X8) %>% 
#   mutate(X8 = str_remove(X8, "\\sf\\.[0-9]{1,}")) %>% 
#   mutate(year_date = year(ymd(X3))) %>% 
#   mutate(folio = str_remove(X8, "f\\.[0-9]{1}")) %>% 
#   filter(!is.na(folio)) %>% 
#   mutate(folio = trimws(folio, which = 'both'))
# results_80 = list()
# for(i in 1:100){
#   
# sample_edges = network_filtered_f %>%
# sample_frac((100-20)/100, replace = F) %>%
# distinct(.[1], .[2])
# 
# sub.graphmatr = graph_from_data_frame(sample_edges)
# 
# 
# d = sub.graphmatr %>% as_tbl_graph() %>% 
#   mutate(degree = centrality_degree(mode = 'total')) %>% 
#   mutate(betweenness = centrality_betweenness()) %>% 
#   mutate(d_b = betweenness/degree) %>% 
#   filter(degree>10) %>% 
#   as_tibble() %>%
#   mutate(run = i)
# 
# results_80[[i]] = d
# 
# }
# 
# library(data.table)
# 
# results_80 = results_80 %>% rbindlist()
# 
# results_80 =results_80 %>% 
#   group_by(run) %>% 
#   mutate(rank_degree = rank(-degree)) %>% 
#   mutate(rank_between = rank(-betweenness))  %>% 
#   mutate(rank_d_b = rank(-d_b)) %>% group_by(name) %>%
#   mutate(min_rank = min(rank_d_b))
# 
# 
# 
# results_50 = list()
# for(i in 1:100){
#   
# sample_edges = network_filtered_f %>%
# sample_frac((100-50)/100, replace = F) %>%
# distinct(.[1], .[2])
# 
# sub.graphmatr = graph_from_data_frame(sample_edges)
# 
# 
# d = sub.graphmatr %>% as_tbl_graph() %>% 
#   mutate(degree = centrality_degree(mode = 'total')) %>% 
#   mutate(betweenness = centrality_betweenness()) %>% 
#   mutate(d_b = betweenness/degree) %>% 
#   filter(degree>10) %>% 
#   as_tibble() %>%
#   mutate(run = i)
# 
# results_50[[i]] = d
# 
# }
# 
# 
# 
# results_50 = results_50 %>% rbindlist()
# 
# results_50 =results_50 %>% 
#   group_by(run) %>% 
#   mutate(rank_degree = rank(-degree)) %>% 
#   mutate(rank_between = rank(-betweenness))  %>% 
#   mutate(rank_d_b = rank(-d_b)) %>% group_by(name) %>%
#   mutate(min_rank = min(rank_d_b))
# 
# results_20 = list()
# for(i in 1:100){
#   
# sample_edges = network_filtered_f %>%
# sample_frac((100-80)/100, replace = F) %>%
# distinct(.[1], .[2])
# 
# sub.graphmatr = graph_from_data_frame(sample_edges)
# 
# 
# d = sub.graphmatr %>% as_tbl_graph() %>% 
#   mutate(degree = centrality_degree(mode = 'total')) %>% 
#   mutate(betweenness = centrality_betweenness()) %>% 
#   mutate(d_b = betweenness/degree) %>% 
#   filter(degree>10) %>% 
#   as_tibble() %>%
#   mutate(run = i)
# 
# results_20[[i]] = d
# 
# }
# 
# library(data.table)
# 
# results_20 = results_20 %>% rbindlist()
# 
# results_20 =results_20 %>% 
#   group_by(run) %>% 
#   mutate(rank_degree = rank(-degree)) %>% 
#   mutate(rank_between = rank(-betweenness))  %>% 
#   mutate(rank_d_b = rank(-d_b)) %>% group_by(name) %>%
#   mutate(min_rank = min(rank_d_b))
# 


load('results_20')
load('results_50')
load('results_80')



sec_of_state_ranks = rbind(results_50 %>% 
                                    mutate(amount = '50% Remaining'), results_80%>% 
                                    mutate(amount = '80% Remaining'), results_20 %>% 
                             mutate(amount = '20% Remaining')) %>% filter( name%in% c('42999', '18912','41287'))

sec_of_state_ranks$f_amount = factor(sec_of_state_ranks$amount, levels = c('80% Remaining', '50% Remaining','20% Remaining' ))

```

How might the results described above impact a real-world analysis of an historical network? To understand the effect these numbers might have on actual findings, we used the same sampling strategy but looked at its effect on individual nodes. Two examples are presented here. First, a historical argument we on the project team are making using this data rests in part on the specific rankings of three key Secretaries of State: Joseph Williamson, Lord Arlington, and Edward Nicholas. Using the same sampling methods as above, we calculated the ranks for these nodes with 80% and 50% of the network remaining, 100 separate times. Through this we see that the effect on basic network measures on some of the highest-ranking nodes was remarkably minimal, even with 50% missing (figure \@ref(fig:secOfState)).

```{r secOfState, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="To demonstrate the effect of missing data on individual network results, we calculated the degree ranks of three Secretaries of State at 20, 50 and 80 per cent of the network remaining, run with 100 random samples. The rankings of all three stayed remarkably similar, even with only 20% of letters remaining.", cache = TRUE, fig.height=3, fig.width=4}

spo_mapped_people = read_delim('/Users/Yann/Documents/GitHub/cumulative_contacts/cumulative_contacts/data/people_docs_stuart_200421', delim = '\t', col_names = F) %>% mutate(X1 = as.character(X1))


p = ggplot() + 
  geom_point(data =sec_of_state_ranks %>% 
  left_join(spo_mapped_people %>% 
              select(X1, X2), by = c('name' = 'X1')) , aes(x = run, y = rank_degree, color = X2), alpha = .8) + facet_wrap(~f_amount) + scale_y_reverse(breaks = 1:15)+
  theme_bw()+ theme(legend.position = 'bottom') +labs(color = NULL) + guides(color = guide_legend(nrow = 2))
  
p+ theme(text = element_text(family = 'Times'))

```

In order to fully assess robustness we ran an experiment specifically tailored towards findings using lower-ranking individuals. Ahnert and Ahnert (2019) compared betweenness centrality and degree to highlight a group of often-overlooked bridging nodes: those whose importance lay not in their total connections, but in their capacity to bridge separate parts of the network together.[@ahnert_metadata_2019] In that paper individuals were highlighted by plotting degree and betweenness centrality ranks and looking for those significantly below the trend line.

Doing this for SPO reveals James Butler, Duke of Ormond as a classic example of one of these bridges. From an 'Old English' family born in London, Butler bridged several networks both politically and temporally: not only was he a connecting link between the English and Irish nobility, he was one of the few high-ranking politicians with a significant career both before the Civil War *and* following the Restoration of Charles II in 1660. Thus, despite his relatively low degree (ranked 226th), his betweenness centrality is proportionately high (ranked 38th), indicating his value as a 'bridge' in the network. This is clearly seen in the scatterplot below (figure \@ref(fig:degreeBetween)).

To estimate the effect of missing data on Ormond's status as a 'person of interest' with this visual method, we again simulated removing 20%, 50% and 80% of the data, 100 times, and reproduced the scatterplot above for each run. The result shows that Ormond's position remains in the same average 'area' of the scatter plot each time, particularly when 20% or 50% of the network is removed. With 80% of the network removed, Butler's position as an outlier is only severely wrong in *one* out of the 100 runs.

```{r degreeBetween, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Assessing the effect of data loss on a downstream task. James Butler, Earl of Ormond can be described as a 'bridge' node in State Papers Online: neither his degree or betweenness centrality scores are within the highest-ranking, but his betweenness centrality is proportionately high in comparison to his degree. This can be seen from his position well into the lower half in a scatterplot of the rankings of the two measurements in (a), which plot the rank of his betweenness centrality against his degree, on a log-log plot. In (b), (c) and (d) we calculated his position with 20%, 50% and 80% of the network removed, respectively. This was done 100 times and the results plotted one over another, with Ormond highlighted. In almost all cases, as can be seen here, he remains roughly in the same area of the scatterplot.",fig.width = 6, fig.height=4}

library(cowplot)
set.seed(1234)
spo_raw = read_delim('fromto_all_place_mapped_stuart_sorted', delim = '\t', col_names = F)
network_filtered = spo_raw %>% 
  dplyr::select(X1, X2, X3, X8) %>% 
  mutate(X8 = str_remove(X8, "\\sf\\.[0-9]{1,}")) %>% 
  mutate(year_date = year(ymd(X3)))

network_filtered_f = spo_raw %>% 
  dplyr::select(X1, X2, X3, X8) %>% 
  mutate(X8 = str_remove(X8, "\\sf\\.[0-9]{1,}")) %>% 
  mutate(year_date = year(ymd(X3))) %>% 
  mutate(folio = str_remove(X8, "f\\.[0-9]{1}")) %>% 
  filter(!is.na(folio)) %>% 
  mutate(folio = trimws(folio, which = 'both'))

nsim =1
graphmatr = graph_from_data_frame(network_filtered_f %>%
                                    distinct(.[1], .[2]), directed = T)

nodes = graphmatr %>% 
  as_tbl_graph() %>% 
  mutate(degree =centrality_degree(mode = 'total')) %>% 
 # filter(degree>1) %>%
  activate(nodes) %>% as_tibble() %>% pull(name)

network_filtered_f = spo_raw %>% 
  dplyr::select(X1, X2, X3, X8) %>% 
  mutate(X8 = str_remove(X8, "\\sf\\.[0-9]{1,}")) %>% 
  mutate(year_date = year(ymd(X3))) %>% 
  mutate(folio = str_remove(X8, "f\\.[0-9]{1}")) %>% 
  filter(!is.na(folio)) %>% 
  mutate(folio = trimws(folio, which = 'both')) %>% 
  filter(X1 %in% nodes |X2 %in% nodes)

graphmatr = graph_from_data_frame(network_filtered_f %>%
distinct(.[1], .[2]), directed = T)

all_ranks = rbind(results_50 %>% 
                                    mutate(amount = '50% Remaining'), results_80%>% 
                                    mutate(amount = '80% Remaining'), results_20 %>% 
                             mutate(amount = '20% Remaining')) %>% mutate(butler = ifelse( name == '20751', 'yes', 'no'))


full_results_for_butler = network_filtered_f %>% distinct(X1, X2) %>% graph_from_data_frame() %>% as_tbl_graph() %>% 
  mutate(degree = centrality_degree(mode = 'total')) %>% 
  mutate(betweenness = centrality_betweenness()) %>% 
  mutate(d_b = betweenness/degree)  %>% 
  filter(degree>10)%>% 
  as_tibble()%>% 
  mutate(rank_degree = rank(-degree)) %>% 
  mutate(rank_between = rank(-betweenness))  %>% 
  mutate(rank_d_b = rank(-d_b)) %>% group_by(name) %>%
  mutate(min_rank = min(rank_d_b))


  a = ggplot(data = full_results_for_butler %>% 
  mutate(butler = ifelse( name == '20751', 'yes', 'no'))) + 
  geom_point(aes(x = degree, 
                 y = rank_between, 
                 color = butler, alpha = butler)) + 
  scale_alpha_manual(values = c(.3, .9))  +
  annotate("segment", x = 56, xend = 56, y = 3, yend = 30,
           colour = "black", size =.3, arrow = arrow(length = unit(0.05, "inches"),
      ends = "last", type = "closed")) +
  annotate("text", x = 56,  y = 2, label = 'James Butler',
           colour = "black", size = 2.5)+ theme_bw() + theme(legend.position = 'none') + scale_x_log10(limits = c(10,2336)) + scale_y_log10()  + coord_cartesian() + theme(text = element_text(family = 'Times'))

b = results_80 %>% mutate(butler = ifelse( name == '20751', 'yes', 'no')) %>% 
  ggplot() + 
  geom_point(aes(x = degree, 
                 y = rank_between, 
                 group = run, 
                 color = butler, alpha = butler))+
  scale_alpha_manual(values = c(.01, .8)) + theme_bw() + theme(legend.position = 'none') + scale_x_log10(limits = c(10,2336)) + scale_y_log10()   + theme(text = element_text(family = 'Times'))

c = results_50 %>% mutate(butler = ifelse( name == '20751', 'yes', 'no')) %>% 
  ggplot() + 
  geom_point(aes(x = degree, 
                 y = rank_between, 
                 group = run, 
                 color = butler, alpha = butler))+ 
  scale_alpha_manual(values = c(.01, .8)) + theme_bw() + 
  theme(legend.position = 'none') + 
  scale_x_log10(limits = c(10,2336)) + scale_y_log10()  +
  theme(text = element_text(family = 'Times'))

d = results_20 %>% mutate(butler = ifelse( name == '20751', 'yes', 'no')) %>% 
  ggplot() + 
  geom_point(aes(x = degree, 
                 y = rank_between, 
                 group = run, 
                 color = butler, alpha = butler)) + 
  scale_alpha_manual(values = c(.01, .8)) + theme_bw() + 
  theme(legend.position = 'none') +
  scale_x_log10(limits = c(10,2336)) + scale_y_log10()  + 
  theme(text = element_text(family = 'Times'))

plot_grid(a,b,c,d, labels = c('a', 'b', 'c', 'd'),label_fontface = "bold", label_size = 12, label_fontfamily = 'Times')



```

# Shiny Application   

To help other researchers working with historical correspondence archives to assess the impact of data loss, we have made available a user-friendly implementation of the code used in this article, which can be used to assess and compare the robustness of a set of network measures of any network. This application, developed using R and Shiny, allows a user to upload a simple network structure—an edge list—and run the same analyses as in this paper, specifying the number of iterations to run (figure \@ref(fig:screenshot)). If the edges have further attributes (for example folio names or other source information) the impact of removing samples of these attributes on robustness results will also be calculated by the application. 

```{r screenshot, echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Screenshot of Network Robustness Application, made with Shiny", fig.height=4, fig.width=4.5}
library(png)
library(grid)
img <- readPNG("Screenshot 2021-03-23 at 17.50.43.png")
 grid.raster(img)
```


# Conclusions

It is worth noting that the use of historical network analysis is multi-faceted and it should be stressed that the results that apply to the networks studied here---based on correspondence data and with a 'long tail' distribution of letters weighted heavily towards a small number of nodes---may not apply to other sorts of network data such as co-occurence networks. Furthermore, many historical network studies have used global measurements such as assortivity, global clustering coefficients and so forth. [for example @lincoln_continuity_2017; @grandjean_les_2018] The robustness of these metrics and network types would require further research. Historical correspondence network data (as indeed most network data - see Introduction) is always incomplete: this may be because of gaps in archives, the lack of digitisation, or simply because most communication is face-to-face and therefore leaves little record. There is a subset of more mundane 'knowable' missing archival data, related in the first instance to its materiality as well as its editorial and digital afterlives: the missing data within it is from lost letters, burned books, uncalendared State papers, undigitised editions, uncrackable ciphers, and so forth which we can model and understand its impact on findings. Modelling the effect of missing letters is an enterprise which, as we have shown, can help to deal with the problem in the absence of reconstructed archives. 

[^4]: See *The Correspondence of Henry Oldenburg*, ed. A. R. Hall and M. B. Hall, 13 vols (Madison, WI: University of Wisconsin Press; London: Mansel; London: Taylor & Francis, 1965--86) and for a specific example from EMLO <https://tinyurl.com/y8lfdvha>

The results here show that even with very large numbers of letters missing, there is suprisingly little effect on the overall network structure—or rankings—of many key network metrics. Researchers doing historical network analysis on partial data, if they are content that their data loss is random, may be able to draw concrete conclusions from just 20% of surviving letters. The experiments above show that different modes of removal have different effects, and that missing correspondence data which affects edges (i.e. missing letters) is more robust than those affecting nodes (such as missing individuals, folios or catalogues). This should also be taken into account when considering the impact of their partial data.

In terms of specific metrics, we conclude that researchers using similarly-shaped datasets for historical network analysis might use caution in the interpretation of eigenvector centrality or transitivity measures if it is thought that there is significant relevant data which are yet to be found or digitised, and use another, more robust measurement instead—particularly if the 'missingness' is node-based. The experiments carried out here show that for historical network analysis on correspondence networks, the 'shape' of the loss has also been shown to have surprisingly little effect on common real-world downstream tasks. Many of the key findings we as authors have relied on using network analysis would be relatively unchanged even with significant data loss. The rankings of three key nodes hardly change position in some key network centrality rankings even with 80% of the network removed. Furthermore, this robustness is not just applicable to those at the very top of the rankings, either: in a second test, an outlying though not particularly high-ranking node, James Butler, Duke of Ormond maintained his outlier status despite significant data loss as an individual whose betweenness centrality was proportionately high when plotted against his degree in the SPO network. 

The 'archival turn' suggests that we should consider archives as multi-dimensional textual objects which need to be interpreted rather than neutral silos of documents to be mined for useful information [see @walsham2018; @ketelaar2001] If this is the case, we should bring our quantitative toolsets and 'read' them at scale much like the more traditional texts which are often the subject of digital humanities. Digital Humanities as a field has been much concerned with representativeness: Andrew Piper, arguing that because culture is 'never finished', there should be a move away from thinking about 'samples' and 'bias' and towards what he terms representativeness: a mode which says that every part is a representation, and in which we focus on the curation of data rather than its quantity (or completeness). We suggest that an important facet of this data curation is to understand its missingness, and, moreover, where possible, the effect that this might have on resulting quantitative results, whether they be, as in this case, network metrics, but also more generally: the same technique might be applied to measures derived from work in Computational Literary Studies or Spatial Humanities. The robustness of the arguments that a scholar builds upon such results depends much more on the historical scholarship employed in their interpretation than on the incompleteness of the underlying data. It follows that historical argument must take archival absences into account, regardless of whether its foundations are quantitative or not.

# References {.unnumbered}

::: {#refs}
:::

\newpage

# Appendix {.unnumbered}

Additional results produced by the robustness analysis (including those used above), including in-degree, out-degree, and closeness centrality. As in the main plots, blue line indicates the mean and the limits of the gray area the standard deviation.

## Full Results - Early Modern Letters Online (EMLO)

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.height = 8, fig.width=12}
robustness_results %>% 
  mutate(metric = str_remove(metric, "original_catalogue_name_|none_|year_date_|nodes_")) %>%
  mutate(metric = ifelse(metric == 'degree' | metric == 'degree_total', 'Degree', metric)) %>%
  mutate(metric = ifelse(metric == 'eigen', 'Eigenvector', metric)) %>%
  mutate(metric = ifelse(metric == 'transitivity', 'Transitivity', metric)) %>% 
  mutate(metric = ifelse(metric == 'closeness', 'close', metric)) %>% 
  mutate(metric = ifelse(metric == 'betweenness', 'Betweenness', metric))%>% 
  mutate(metric = ifelse(metric == 'close', 'Closeness', metric))%>% 
  mutate(metric = ifelse(metric == 'degree_in', 'In-degree', metric)) %>%
  mutate(metric = ifelse(metric == 'degree_out', 'Out-degree', metric)) %>%
  as_tibble() %>% 
  mutate(instance = 1:nrow(.)) %>% 
    mutate(type = ifelse(type == 'letter_id', 'letter',
                             ifelse(type == 'folio_or_catalogue', 'catalogue', 
                                    ifelse(type == 'folio', 'catalogue/folio',
                                           ifelse(type == 'year_date', 'year', type))))) %>% 
  mutate(dataset = ifelse(dataset == 'emlo', 'EMLO',
                          ifelse(dataset == 'bcc', 'BCC', 'SPO')))%>% 
  filter(dataset == 'EMLO') %>% 
  rename(`Removal Type` = type) %>%
 # filter(`Removal Type` == 'letter') %>% 
 # filter(metric %in% c('Degree', 'Eigenvector', 'Transitivity','Betweenness')) %>%  
  group_by(metric, dataset, `Removal Type`, sample) %>% 
  summarise(mean = mean(cor), min = min(cor), max = max(cor),sd = sd(cor)) %>% 
  ggplot() + 
  geom_ribbon(aes(x = sample, ymax = mean+sd, ymin = mean-sd), alpha = .6, fill = 'gray75')  + 
   geom_line(aes(x = sample, y = mean), alpha = .8, color = 'blue') +
  labs(x = 'Percentage Removed', y = "Spearman's Rho") + 
  theme_bw() +
  coord_fixed(100,ylim = c(0,1)) + 
  facet_grid(dataset~`Removal Type`~metric) + 
  scale_color_viridis_d()  +
  scale_y_continuous(breaks = c(.5, 1))  +
  scale_x_continuous(breaks = c(50, 100)) + 
  theme(panel.grid.minor =element_blank(), 
        strip.text = element_text(size = 16), 
        text = element_text(family = 'Times', size = 14))
```

\newpage

## Full Results - State Papers Online (SPO)

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.height = 8, fig.width=12}
robustness_results %>% 
  mutate(metric = str_remove(metric, "original_catalogue_name_|none_|year_date_|nodes_")) %>%
  mutate(metric = ifelse(metric == 'degree' | metric == 'degree_total', 'Degree', metric)) %>%
  mutate(metric = ifelse(metric == 'eigen', 'Eigenvector', metric)) %>%
  mutate(metric = ifelse(metric == 'transitivity', 'Transitivity', metric)) %>% 
  mutate(metric = ifelse(metric == 'closeness', 'close', metric)) %>% 
  mutate(metric = ifelse(metric == 'betweenness', 'Betweenness', metric))%>% 
  mutate(metric = ifelse(metric == 'close', 'Closeness', metric))%>% 
  mutate(metric = ifelse(metric == 'degree_in', 'In-degree', metric)) %>%
  mutate(metric = ifelse(metric == 'degree_out', 'Out-degree', metric)) %>%
  as_tibble() %>% 
  mutate(instance = 1:nrow(.)) %>% 
    mutate(type = ifelse(type == 'letter_id', 'letter',
                             ifelse(type == 'original_catalogue_name', 'catalogue/folio', 
                                    ifelse(type == 'folio_or_catalogue', 'folio',
                                           ifelse(type == 'year_date', 'year', type))))) %>% 
  mutate(dataset = ifelse(dataset == 'emlo', 'EMLO',
                          ifelse(dataset == 'bcc', 'BCC', 'SPO')))%>% 
  rename(`Removal Type` = type) %>%
  filter(dataset == 'SPO') %>% 
 # filter(`Removal Type` == 'letter') %>% 
 # filter(metric %in% c('Degree', 'Eigenvector', 'Transitivity','Betweenness')) %>%  
  group_by(metric, dataset, `Removal Type`, sample) %>% 
  summarise(mean = mean(cor), min = min(cor), max = max(cor),sd = sd(cor)) %>% 
  ggplot() + 
  geom_ribbon(aes(x = sample, ymax = mean+sd, ymin = mean-sd), alpha = .6, fill = 'gray75')  + 
   geom_line(aes(x = sample, y = mean), alpha = .8, color = 'blue') +
  labs(x = 'Percentage Removed', y = "Spearman's Rho") + 
  theme_bw() +
  coord_fixed(100,ylim = c(0,1)) + 
  facet_grid(dataset~`Removal Type`~metric) + 
  scale_color_viridis_d()  +
  scale_y_continuous(breaks = c(.5, 1))  +
  scale_x_continuous(breaks = c(50, 100)) + 
  theme(panel.grid.minor =element_blank(), 
        strip.text = element_text(size = 16), 
        text = element_text(family = 'Times', size = 14))
```

\newpage

## Full Results - Bodleian Card Catalogue (BCC)

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.height = 8, fig.width=12}
robustness_results %>% 
  mutate(metric = str_remove(metric, "original_catalogue_name_|none_|year_date_|nodes_")) %>%
  mutate(metric = ifelse(metric == 'degree' | metric == 'degree_total', 'Degree', metric)) %>%
  mutate(metric = ifelse(metric == 'eigen', 'Eigenvector', metric)) %>%
  mutate(metric = ifelse(metric == 'transitivity', 'Transitivity', metric)) %>% 
  mutate(metric = ifelse(metric == 'closeness', 'close', metric)) %>% 
  mutate(metric = ifelse(metric == 'betweenness', 'Betweenness', metric))%>% 
  mutate(metric = ifelse(metric == 'close', 'Closeness', metric))%>% 
  mutate(metric = ifelse(metric == 'degree_in', 'In-degree', metric)) %>%
  mutate(metric = ifelse(metric == 'degree_out', 'Out-degree', metric)) %>%
  as_tibble() %>% 
  mutate(instance = 1:nrow(.)) %>% 
    mutate(type = ifelse(type == 'letter_id', 'letter',
                             ifelse(type == 'original_catalogue_name', 'catalogue/folio', 
                                    ifelse(type == 'folio_or_catalogue', 'folio',
                                           ifelse(type == 'year_date', 'year', type))))) %>% 
  mutate(dataset = ifelse(dataset == 'emlo', 'EMLO',
                          ifelse(dataset == 'bcc', 'BCC', 'SPO'))) %>% 
  rename(`Removal Type` = type) %>%
  filter(dataset == 'BCC') %>% 
 # filter(`Removal Type` == 'letter') %>% 
 # filter(metric %in% c('Degree', 'Eigenvector', 'Transitivity','Betweenness')) %>%  
  group_by(metric, dataset, `Removal Type`, sample) %>% 
  summarise(mean = mean(cor), min = min(cor), max = max(cor),sd = sd(cor)) %>% 
  ggplot() + 
  geom_ribbon(aes(x = sample, ymax = mean+sd, ymin = mean-sd), alpha = .6, fill = 'gray75')  + 
   geom_line(aes(x = sample, y = mean), alpha = .8, color = 'blue') +
  labs(x = 'Percentage Removed', y = "Spearman's Rho") + 
  theme_bw() +
  coord_fixed(100,ylim = c(0,1)) + 
  facet_grid(dataset~`Removal Type`~metric) + 
  scale_color_viridis_d()  +
  scale_y_continuous(breaks = c(.5, 1))  +
  scale_x_continuous(breaks = c(50, 100)) + 
  theme(panel.grid.minor =element_blank(), 
        strip.text = element_text(size = 16), 
        text = element_text(family = 'Times', size = 14))
```

## Sample results for dataset

```{r example, echo=FALSE, message=FALSE, warning=FALSE, fig.cap = "Two example comparisons of each centrality score, with 80% and 50% of letters removed at random, displaying a monotonic relationship between the data and therefore suitable for Spearman's rank correlation. Even with large numbers of letters removed, Spearman's rho value remains high", fig.height=8, fig.width=3.5}


e_bw.g <- igraph::eigen_centrality(graphmatr)['vector'][[1]]
d_bw.g <- igraph::degree(graphmatr, mode = 'total')
d_i_bw.g <- igraph::degree(graphmatr, mode = 'in')
d_o_bw.g <- igraph::degree(graphmatr, mode = 'out')
b_bw.g <- igraph::betweenness(graphmatr)


sample_edges = network_filtered_f %>%
sample_frac((100-50)/100, replace = F) %>%
distinct(.[1], .[2])

sub.graphmatr = graph_from_data_frame(sample_edges)


e_temp.stats_50 = igraph::eigen_centrality(sub.graphmatr)['vector'][[1]] %>% tibble::enframe()
e_temp.stats_50$full = e_bw.g[e_temp.stats_50$name]
e_temp.stats_50$metric = 'eigen'

d_temp.stats_50 = igraph::degree(sub.graphmatr, mode = 'total') %>% tibble::enframe()
d_temp.stats_50$full = d_bw.g[d_temp.stats_50$name]
d_temp.stats_50$metric = 'degree-total'

d_i_temp.stats_50 = igraph::degree(sub.graphmatr, mode = 'in') %>% tibble::enframe()
d_i_temp.stats_50$full = d_i_bw.g[d_i_temp.stats_50$name]
d_i_temp.stats_50$metric = 'degree-in'

d_o_temp.stats_50 = igraph::degree(sub.graphmatr, mode = 'out') %>% tibble::enframe()
d_o_temp.stats_50$full = d_o_bw.g[d_o_temp.stats_50$name]
d_o_temp.stats_50$metric = 'degree-out'

b_temp.stats_50 = igraph::betweenness(sub.graphmatr) %>% tibble::enframe()
b_temp.stats_50$full = b_bw.g[b_temp.stats_50$name]
b_temp.stats_50$metric = 'betweenness'



graphmatr = graph_from_data_frame(network_filtered_f %>%
                                    distinct(.[1], .[2]), directed = T)

e_bw.g <- igraph::eigen_centrality(graphmatr)['vector'][[1]]
d_bw.g <- igraph::degree(graphmatr, mode = 'total')
d_i_bw.g <- igraph::degree(graphmatr, mode = 'in')
d_o_bw.g <- igraph::degree(graphmatr, mode = 'out')
b_bw.g <- igraph::betweenness(graphmatr)

sample_edges = network_filtered_f %>%
  sample_frac((100-90)/100, replace = F) %>%
  distinct(.[1], .[2])

sub.graphmatr = graph_from_data_frame(sample_edges)

e_temp.stats_20 = igraph::eigen_centrality(sub.graphmatr)['vector'][[1]] %>% tibble::enframe()
e_temp.stats_20$full = e_bw.g[e_temp.stats_20$name]
e_temp.stats_20$metric = 'eigen'

d_temp.stats_20 = igraph::degree(sub.graphmatr, mode = 'total') %>% tibble::enframe()
d_temp.stats_20$full = d_bw.g[d_temp.stats_20$name] 
d_temp.stats_20$metric = 'degree-total'

d_i_temp.stats_20 = igraph::degree(sub.graphmatr, mode = 'in') %>% tibble::enframe()
d_i_temp.stats_20$full = d_i_bw.g[d_i_temp.stats_20$name]
d_i_temp.stats_20$metric = 'degree-in'

d_o_temp.stats_20 = igraph::degree(sub.graphmatr, mode = 'out') %>% tibble::enframe()
d_o_temp.stats_20$full = d_o_bw.g[d_o_temp.stats_20$name]
d_o_temp.stats_20$metric = 'degree-out'

b_temp.stats_20 = igraph::betweenness(sub.graphmatr) %>% tibble::enframe()
b_temp.stats_20$full = b_bw.g[b_temp.stats_20$name]
b_temp.stats_20$metric = 'betweenness'


e_p20 = cor.test(e_temp.stats_20$value, e_temp.stats_20$full, method = 'spearman')$estimate['rho']
e_p50 = cor.test(e_temp.stats_50$value, e_temp.stats_50$full, method = 'spearman')$estimate['rho']

d_p20 = cor.test(d_temp.stats_20$value, d_temp.stats_20$full, method = 'spearman')$estimate['rho']
d_p50 = cor.test(d_temp.stats_50$value, d_temp.stats_50$full, method = 'spearman')$estimate['rho']

d_i_p20 = cor.test(d_i_temp.stats_20$value, d_i_temp.stats_20$full, method = 'spearman')$estimate['rho']
d_i_p50 = cor.test(d_i_temp.stats_50$value, d_i_temp.stats_50$full, method = 'spearman')$estimate['rho']

d_o_p20 = cor.test(d_o_temp.stats_20$value, d_o_temp.stats_20$full, method = 'spearman')$estimate['rho']
d_o_p50 = cor.test(d_o_temp.stats_50$value, d_o_temp.stats_50$full, method = 'spearman')$estimate['rho']

b_p20 = cor.test(b_temp.stats_20$value, b_temp.stats_20$full, method = 'spearman')$estimate['rho']
b_p50 = cor.test(b_temp.stats_50$value, b_temp.stats_50$full, method = 'spearman')$estimate['rho']


e_temp.stats_20 = e_temp.stats_20 %>% mutate(remaining = paste0('20% Remaining ', "(r of ", round(e_p20,3), ", p<.01)")) %>% mutate(remain = '20% Remaining')

e_temp.stats_50 = e_temp.stats_50 %>% mutate(remaining = paste0('50% Remaining ', "(r of ",round(e_p50,3), ", p<.01)")) %>% mutate(remain = '50% Remaining')

d_temp.stats_20 = d_temp.stats_20 %>% mutate(remaining = paste0('20% Remaining ', "(r of ", round(d_p20,3), ", p<.01)")) %>% mutate(remain = '20% Remaining')

d_temp.stats_50 = d_temp.stats_50 %>% mutate(remaining = paste0('50% Remaining ', "(r of ",round(d_p50,3), ", p<.01)")) %>% mutate(remain = '50% Remaining')

d_i_temp.stats_20 = d_i_temp.stats_20 %>% mutate(remaining = paste0('20% Remaining ', "(r of ", round(d_i_p20,3), ", p<.01)")) %>% mutate(remain = '20% Remaining')

d_i_temp.stats_50 = d_i_temp.stats_50 %>% mutate(remaining = paste0('50% Remaining ', "(r of ",round(d_i_p50,3), ", p<.01)")) %>% mutate(remain = '50% Remaining')

d_o_temp.stats_20 = d_o_temp.stats_20 %>% mutate(remaining = paste0('20% Remaining ', "(r of ", round(d_o_p20,3), ", p<.01)")) %>% mutate(remain = '20% Remaining')

d_o_temp.stats_50 = d_o_temp.stats_50 %>% mutate(remaining = paste0('50% Remaining ', "(r of ",round(d_o_p50,3), ", p<.01)")) %>% mutate(remain = '50% Remaining')

b_temp.stats_20 = b_temp.stats_20 %>% mutate(remaining = paste0('20% Remaining ', "(r of ", round(b_p20,3), ", p<.01)")) %>% mutate(remain = '20% Remaining')

b_temp.stats_50 = b_temp.stats_50 %>% mutate(remaining = paste0('50% Remaining ', "(r of ",round(b_p50,3), ", p<.01)")) %>% mutate(remain = '50% Remaining')

a = rbind(e_temp.stats_20, e_temp.stats_50) %>% ggplot() + 
  geom_point(aes(x = value, y = full), size = .5, alpha  = .6) + 
  facet_wrap(metric~remaining, scales = 'free_x') + 
  theme_bw() + 
  theme(text = element_text(family = 'Times')) + 
  labs(x = 'Sample Network', y = 'Full Network' )

b = rbind(
      d_temp.stats_20, d_temp.stats_50) %>% ggplot() + 
  geom_point(aes(x = value, y = full), size = .5, alpha  = .6) + 
  facet_wrap(metric~remaining, scales = 'free_x') + 
  theme_bw() + 
  theme(text = element_text(family = 'Times')) + 
  labs(x = 'Sample Network', y = 'Full Network' )

c = rbind(
      d_i_temp.stats_20, d_i_temp.stats_50) %>% ggplot() + 
  geom_point(aes(x = value, y = full), size = .5, alpha  = .6) + 
  facet_wrap(metric~remaining, scales = 'free_x') + 
  theme_bw() + 
  theme(text = element_text(family = 'Times')) + 
  labs(x = 'Sample Network', y = 'Full Network' )

d = rbind(
      d_o_temp.stats_20, d_o_temp.stats_50) %>% ggplot() + 
  geom_point(aes(x = value, y = full), size = .5, alpha  = .6) + 
  facet_wrap(metric~remaining, scales = 'free_x') + 
  theme_bw() + 
  theme(text = element_text(family = 'Times')) + 
  labs(x = 'Sample Network', y = 'Full Network' )

e = rbind(
      b_temp.stats_20, b_temp.stats_50) %>% ggplot() + 
  geom_point(aes(x = value, y = full), size = .5, alpha  = .6) + 
  facet_wrap(metric~remaining, scales = 'free_x') + 
  theme_bw() + 
  theme(text = element_text(family = 'Times')) + 
  labs(x = 'Sample Network', y = 'Full Network' )

library(cowplot)
plot_grid(a,b,c,d,e, ncol = 1)

```
